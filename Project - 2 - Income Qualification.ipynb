{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Income Qualification\n",
    "#### ADITHYA M.N."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement: \n",
    "**Many social programs have a hard time ensuring that the right people are given enough aid. It’s tricky when a program focuses on the poorest segment of the population. This segment of the population can’t provide the necessary income and expense records to prove that they qualify.**\n",
    "\n",
    "**In Latin America, a popular method called Proxy Means Test (PMT) uses an algorithm to verify income qualification. With PMT, agencies use a model that considers a family’s observable household attributes like the material of their walls and ceiling or the assets found in their homes to**\n",
    "\n",
    "**While this is an improvement, accuracy remains a problem as the region’s population grows and poverty declines.**\n",
    "\n",
    "**The Inter-American Development Bank (IDB)believes that new methods beyond traditional econometrics, based on a dataset of Costa Rican household characteristics, might help improve PMT’s performance.**\n",
    "\n",
    "### Following Actions need to be Performed\n",
    "\n",
    "    1. Identify the output variable.\n",
    "    2. Understand the type of data.\n",
    "    3. Check if there are any biases in your dataset.\n",
    "    4. Check whether all members of the house have the same poverty level.\n",
    "    5. Check if there is a house without a family head.\n",
    "    6. Set poverty level of the members and the head of the house within a family.\n",
    "    7. Count how many null values are existing in columns.\n",
    "    8. Remove null value rows of the target variable.\n",
    "    9. Predict the accuracy using random forest classifier.\n",
    "    10. Check the accuracy using random forest with cross validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.model_selection import KFold,cross_val_score,cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data (9557, 143)\n",
      "\n",
      "             Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  \\\n",
      "0  ID_279628684  190000.0       0      3       0     1       1     0    NaN   \n",
      "1  ID_f29eb3ddd  135000.0       0      4       0     1       1     1    1.0   \n",
      "2  ID_68de51c94       NaN       0      8       0     1       1     0    NaN   \n",
      "3  ID_d671db89c  180000.0       0      5       0     1       1     1    1.0   \n",
      "4  ID_d56d6f5f5  180000.0       0      5       0     1       1     1    1.0   \n",
      "\n",
      "   r4h1  ...  SQBescolari  SQBage  SQBhogar_total  SQBedjefe  SQBhogar_nin  \\\n",
      "0     0  ...          100    1849               1        100             0   \n",
      "1     0  ...          144    4489               1        144             0   \n",
      "2     0  ...          121    8464               1          0             0   \n",
      "3     0  ...           81     289              16        121             4   \n",
      "4     0  ...          121    1369              16        121             4   \n",
      "\n",
      "   SQBovercrowding  SQBdependency  SQBmeaned  agesq  Target  \n",
      "0         1.000000            0.0      100.0   1849       4  \n",
      "1         1.000000           64.0      144.0   4489       4  \n",
      "2         0.250000           64.0      121.0   8464       4  \n",
      "3         1.777778            1.0      121.0    289       4  \n",
      "4         1.777778            1.0      121.0   1369       4  \n",
      "\n",
      "[5 rows x 143 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the dataset\n",
    "df=pd.read_csv('train.csv')\n",
    "print('Shape of the data',df.shape)\n",
    "print()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Data given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_type\n",
       "int64      130\n",
       "float64      8\n",
       "object       5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Understanding the Data given to us at hand.\n",
    "datatyp_df = df.dtypes.reset_index()\n",
    "datatyp_df.columns = ['col_name','col_type']\n",
    "datatyp_df.groupby('col_type').size()\n",
    "# We can infer that there are 3 type of Data in the given dataframe from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking For Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    5996\n",
       "2    1597\n",
       "3    1209\n",
       "1     755\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can understand the biases by looking at the targets if the given dataset.\n",
    "df.Target.value_counts()\n",
    "#From this we can undertand the difference in cases which suggests BIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'v2a1', 'hacdor', 'rooms', 'hacapo', 'v14a', 'refrig', 'v18q',\n",
       "       'v18q1', 'r4h1',\n",
       "       ...\n",
       "       'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin',\n",
       "       'SQBovercrowding', 'SQBdependency', 'SQBmeaned', 'agesq', 'Target'],\n",
       "      dtype='object', length=143)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "#From this we can infer that the total columns in this dataset is 143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre - Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v2a1         6860\n",
       "v18q1        7342\n",
       "rez_esc      7928\n",
       "meaneduc        5\n",
       "SQBmeaned       5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding all the columns which have null values in them. \n",
    "#The Goal is to remove them because sklearn does not accept null values to train any dataset.\n",
    "null_columns=df.columns[df.isnull().any()]\n",
    "df[null_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of null values in v2a1 :  71.7798472323951\n",
      "Percentage of null values in v18q1 :  76.82327090091033\n",
      "Percentage of null values in rez_esc :  82.95490216595167\n",
      "Percentage of null values in meaneduc :  0.05231767290990897\n",
      "Percentage of null values in SQBmeaned :  0.05231767290990897\n"
     ]
    }
   ],
   "source": [
    "print ('Percentage of null values in v2a1 : ', df['v2a1'].isnull().sum()/df.shape[0]*100)\n",
    "print ('Percentage of null values in v18q1 : ', df['v18q1'].isnull().sum()/df.shape[0]*100)\n",
    "print ('Percentage of null values in rez_esc : ', df['rez_esc'].isnull().sum()/df.shape[0]*100)\n",
    "print ('Percentage of null values in meaneduc : ', df['meaneduc'].isnull().sum()/df.shape[0]*100)\n",
    "print ('Percentage of null values in SQBmeaned : ', df['SQBmeaned'].isnull().sum()/df.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 140)\n"
     ]
    }
   ],
   "source": [
    "#Removing the Columns which have more than 50% null values\n",
    "#We can say that these are not immportant to the data. \n",
    "df= df.drop(['v2a1','v18q1','rez_esc'],axis=1) \n",
    "print(df.shape)\n",
    "#Notice the shape has become 140 from 143\n",
    "#This is because we removed the columnns with more than 50% Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meaneduc     0\n",
       "SQBmeaned    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imputing the meaneduc & SQBmeaned columns \n",
    "#We are imputing the data because as already mentioned we have to change the null values  to zero.\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imp.fit(df[['meaneduc','SQBmeaned']])\n",
    "df[['meaneduc','SQBmeaned']]=imp.transform(df[['meaneduc','SQBmeaned']])\n",
    "df[['meaneduc','SQBmeaned']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idhogar</th>\n",
       "      <th>dependency</th>\n",
       "      <th>edjefe</th>\n",
       "      <th>edjefa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9557</td>\n",
       "      <td>9557</td>\n",
       "      <td>9557</td>\n",
       "      <td>9557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2988</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>fd8a6d014</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>13</td>\n",
       "      <td>2192</td>\n",
       "      <td>3762</td>\n",
       "      <td>6230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          idhogar dependency edjefe edjefa\n",
       "count        9557       9557   9557   9557\n",
       "unique       2988         31     22     22\n",
       "top     fd8a6d014        yes     no     no\n",
       "freq           13       2192   3762   6230"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= df.drop(['Id'],axis=1)\n",
    "df.describe(include='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the string values into float as the classifier throws error when it encounters a sting data.\n",
    "df.dependency = df.dependency.replace(to_replace=['yes','no'],value=[0.5,0]).astype('float')\n",
    "median1=np.median(df.edjefe[df.edjefe.isin(['yes','no'])==False].astype('float'))\n",
    "\n",
    "df.edjefe = df.edjefe.replace(to_replace=['yes','no'],value=[median1,0]).astype('float')\n",
    "median2 = np.median(df.edjefa[df.edjefa.isin(['yes','no'])==False].astype('float'))\n",
    "\n",
    "df.edjefa = df.edjefa.replace(to_replace=['yes','no'],value=[median2,0]).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idhogar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>fd8a6d014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          idhogar\n",
       "count        9557\n",
       "unique       2988\n",
       "top     fd8a6d014\n",
       "freq           13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2988\n"
     ]
    }
   ],
   "source": [
    "print(df.idhogar.nunique()) #Returns the number of unique values in the colum idhogar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking whether all members of the house have the same poverty level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       21eb7fcc1\n",
       "1       0e5d7a658\n",
       "2       2c7317ea8\n",
       "3       2b58d945f\n",
       "4       2b58d945f\n",
       "          ...    \n",
       "9552    d6c086aa3\n",
       "9553    d6c086aa3\n",
       "9554    d6c086aa3\n",
       "9555    d6c086aa3\n",
       "9556    d6c086aa3\n",
       "Name: idhogar, Length: 9557, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['idhogar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2988"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['idhogar'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['001ff74ca', '003123ec2', '004616164', '004983866', '005905417',\n",
      "       '006031de3', '006555fe2', '00693f597', '006b64543', '00941f1f4',\n",
      "       ...\n",
      "       'ff250fd6c', 'ff31b984b', 'ff38ddef1', 'ff6d16fd0', 'ff703eed4',\n",
      "       'ff9343a35', 'ff9d5ab17', 'ffae4a097', 'ffe90d46f', 'fff7d6be1'],\n",
      "      dtype='object', name='idhogar', length=2988)\n"
     ]
    }
   ],
   "source": [
    "#Grouping by idhogar we can find the the number of families \n",
    "poverty_level=(df.groupby('idhogar')['Target'].nunique()>1).index\n",
    "print(poverty_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if there is a house without a family head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of families without a house head = Index(['001ff74ca', '003123ec2', '004616164', '004983866', '005905417',\n",
      "       '006031de3', '006555fe2', '00693f597', '006b64543', '00941f1f4',\n",
      "       ...\n",
      "       'ff250fd6c', 'ff31b984b', 'ff38ddef1', 'ff6d16fd0', 'ff703eed4',\n",
      "       'ff9343a35', 'ff9d5ab17', 'ffae4a097', 'ffe90d46f', 'fff7d6be1'],\n",
      "      dtype='object', name='idhogar', length=2988) .\n"
     ]
    }
   ],
   "source": [
    "no_head=(df.groupby('idhogar')['parentesco1'].sum()==0).index;\n",
    "print('Number of families without a house head = {} .'.format(no_head))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the poverty level of the members and the head of the house as same in a family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>r4h2</th>\n",
       "      <th>r4h3</th>\n",
       "      <th>r4m1</th>\n",
       "      <th>...</th>\n",
       "      <th>SQBescolari</th>\n",
       "      <th>SQBage</th>\n",
       "      <th>SQBhogar_total</th>\n",
       "      <th>SQBedjefe</th>\n",
       "      <th>SQBhogar_nin</th>\n",
       "      <th>SQBovercrowding</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>1849</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1849</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>4489</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>8464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>8464</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>289</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>1369</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1369</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hacdor  rooms  hacapo  v14a  refrig  v18q  r4h1  r4h2  r4h3  r4m1  ...  \\\n",
       "0       0      3       0     1       1     0     0     1     1     0  ...   \n",
       "1       0      4       0     1       1     1     0     1     1     0  ...   \n",
       "2       0      8       0     1       1     0     0     0     0     0  ...   \n",
       "3       0      5       0     1       1     1     0     2     2     1  ...   \n",
       "4       0      5       0     1       1     1     0     2     2     1  ...   \n",
       "\n",
       "   SQBescolari  SQBage  SQBhogar_total  SQBedjefe  SQBhogar_nin  \\\n",
       "0          100    1849               1        100             0   \n",
       "1          144    4489               1        144             0   \n",
       "2          121    8464               1          0             0   \n",
       "3           81     289              16        121             4   \n",
       "4          121    1369              16        121             4   \n",
       "\n",
       "   SQBovercrowding  SQBdependency  SQBmeaned  agesq  Target  \n",
       "0         1.000000            0.0      100.0   1849       4  \n",
       "1         1.000000           64.0      144.0   4489       4  \n",
       "2         0.250000           64.0      121.0   8464       4  \n",
       "3         1.777778            1.0      121.0    289       4  \n",
       "4         1.777778            1.0      121.0   1369       4  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_mean=df.groupby('idhogar')['Target'].mean().astype('int64').reset_index().rename(columns={'Target':'Target_mean'})\n",
    "df = df.merge(target_mean,how='left',on='idhogar')\n",
    "df.Target=df.Target_mean\n",
    "df.drop('Target_mean',axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9557, 138)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['idhogar'],axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the x (9557, 137)\n",
      "shape of the y (9557,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Target'],axis=1)\n",
    "print('shape of the x',X.shape)\n",
    "y = df.Target\n",
    "print('shape of the y',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset \n",
    "#and uses averaging to improve the predictive accuracy and control over-fitting.\n",
    "#This Classifier is highly recommended due to its high accuracy and ability to not overfit the data.\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=10)\n",
    "Rand_Forest_Class = RandomForestClassifier(n_estimators=10)\n",
    "Rand_Forest_Class.fit(X_train,y_train)\n",
    "Prediction = Rand_Forest_Class.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the accuracy using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9299163179916318\n",
      "Confusion Matrix\n",
      "[[ 141    8    0    6]\n",
      " [   3  272    7   10]\n",
      " [   5    4  180    9]\n",
      " [  20   33   29 1185]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.91      0.87       155\n",
      "           2       0.86      0.93      0.89       292\n",
      "           3       0.83      0.91      0.87       198\n",
      "           4       0.98      0.94      0.96      1267\n",
      "\n",
      "    accuracy                           0.93      1912\n",
      "   macro avg       0.88      0.92      0.90      1912\n",
      "weighted avg       0.93      0.93      0.93      1912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(Prediction,y_test))\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(Prediction,y_test))\n",
    "print('Classification Report')\n",
    "print(classification_report(Prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using KFold Crossvalidation to validate the performance of the designed classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold accuracy scores : \n",
      " [0.91527197 0.94560669 0.93096234 0.92573222 0.94979079 0.94665272\n",
      " 0.94037657 0.91413613 0.93926702 0.94554974]\n",
      "Mean score : \n",
      " 0.9353346185020482\n"
     ]
    }
   ],
   "source": [
    "Kfold = KFold(n_splits=10 , random_state=1 , shuffle =True)\n",
    "Result =  cross_val_score(estimator=Rand_Forest_Class, \n",
    "                              X=X, \n",
    "                              y=y, \n",
    "                              cv=Kfold, \n",
    "                              scoring='accuracy')\n",
    "\n",
    "\n",
    "print('K-Fold accuracy scores : \\n', Result)\n",
    "print('Mean score : \\n', Result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hence we have verified with KFold CrossValidation that the classifier classifies the data with an accuracy of 93% "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
